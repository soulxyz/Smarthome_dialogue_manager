# å¯¹è¯ç³»ç»Ÿä¸‹ä¸€æ­¥å¼€å‘æ“ä½œæŒ‡å—

## ğŸ“‹ æ–‡æ¡£æ¦‚è¿°

æœ¬æ–‡æ¡£ä¸ºç¨‹åºå‘˜æä¾›æ˜ç¡®çš„ä¸‹ä¸€æ­¥å¼€å‘ä»»åŠ¡æŒ‡å¯¼ï¼ŒåŸºäºå½“å‰é¡¹ç›®çŠ¶æ€ï¼ˆP0æ ¸å¿ƒåŠŸèƒ½å·²å®Œæˆï¼Œ102ä¸ªæµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼‰ï¼Œè¯¦ç»†è¯´æ˜P1æ™ºèƒ½å›é€€æœºåˆ¶çš„å®æ–½æ­¥éª¤ã€‚

## ğŸ¯ 1. ä»»åŠ¡ç›®æ ‡

### ä¸»è¦ç›®æ ‡
å®æ–½P1æ™ºèƒ½å›é€€æœºåˆ¶ï¼Œåœ¨è§„åˆ™å¼•æ“ä½ç½®ä¿¡åº¦æ—¶å¯ç”¨LLMå›é€€ï¼Œæå‡å¤æ‚/æ¨¡ç³ŠæŒ‡ä»¤çš„è¯†åˆ«å‡†ç¡®ç‡ã€‚

### å…·ä½“ç›®æ ‡
- å®ç°LLMæ„å›¾è¯†åˆ«å›é€€åŠŸèƒ½
- å»ºç«‹æˆæœ¬æ§åˆ¶å’Œè¶…æ—¶æœºåˆ¶
- ä¿æŒç³»ç»Ÿç¨³å®šæ€§å’Œæ€§èƒ½
- é€šè¿‡æµ‹è¯•éªŒè¯åŠŸèƒ½æ­£ç¡®æ€§

### æˆåŠŸæŒ‡æ ‡
- LLMå›é€€è§¦å‘ç‡ < 20%
- æœ‰æ•ˆçº æ­£ç‡ > 70%
- P95å“åº”æ—¶å»¶ â‰¤ 2.5s
- è¯†åˆ«å‡†ç¡®ç‡è¾ƒP0æå‡ > 5%

## ğŸ“ 2. åˆ†æ­¥éª¤æ“ä½œæŒ‡å—

### é˜¶æ®µä¸€ï¼šæ ¸å¿ƒåŠŸèƒ½å®ç°ï¼ˆé¢„è®¡4å¤©ï¼‰

#### æ­¥éª¤1ï¼šæ·»åŠ LLMå›é€€é…ç½®å‚æ•°

**æ“ä½œä½ç½®**ï¼š`dialogue_manager/engine.py` - `EngineConfig` ç±»

**å…·ä½“æ“ä½œ**ï¼š
```python
# åœ¨ EngineConfig ç±»ä¸­æ·»åŠ ä»¥ä¸‹é…ç½®é¡¹
min_confidence_for_llm: float = 0.4  # LLMå›é€€è§¦å‘é˜ˆå€¼
llm_fallback_enabled: bool = True    # LLMå›é€€å¼€å…³
llm_timeout: int = 3                 # LLMè°ƒç”¨è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
per_turn_max_tokens: int = 500       # å•è½®æœ€å¤§tokenæ•°
per_session_budget: int = 1000       # å•ä¼šè¯é¢„ç®—é™åˆ¶
```

**éªŒè¯æ–¹æ³•**ï¼š
- è¿è¡Œç°æœ‰æµ‹è¯•ç¡®ä¿é…ç½®åŠ è½½æ­£å¸¸
- æ£€æŸ¥é…ç½®é¡¹æ˜¯å¦æ­£ç¡®åˆå§‹åŒ–

#### æ­¥éª¤2ï¼šå®ç°LLMæ„å›¾è¯†åˆ«æ–¹æ³•

**æ“ä½œä½ç½®**ï¼š`dialogue_manager/engine.py` - `DialogueEngine` ç±»

**å…·ä½“æ“ä½œ**ï¼š
1. æ·»åŠ  `_get_intent_from_llm` æ–¹æ³•
2. æ·»åŠ  `_build_llm_intent_prompt` æ–¹æ³•
3. æ·»åŠ  `_parse_llm_intent_response` æ–¹æ³•
4. æ·»åŠ  `_create_unknown_intent_result` æ–¹æ³•

**ä»£ç æ¨¡æ¿**ï¼š
```python
def _get_intent_from_llm(self, user_input: str, context: Dict, debug_info: Dict) -> Dict:
    """ä½¿ç”¨LLMè¿›è¡Œæ„å›¾è¯†åˆ«çš„å›é€€æœºåˆ¶"""
    try:
        # æ„å»ºLLMæç¤º
        prompt = self._build_llm_intent_prompt(user_input, context)
        
        # è°ƒç”¨LLM API
        api_response = self.api_client.chat_completion(
            [{"role": "user", "content": prompt}],
            max_tokens=self.config.per_turn_max_tokens
        )
        
        # è®°å½•APIè°ƒç”¨
        debug_info["api_calls"].append({
            "success": api_response.success,
            "content": api_response.content,
            "error": api_response.error_message,
            "response_time": api_response.response_time,
            "request": {
                "prompt": prompt, 
                "model": self.api_client.model_id, 
                "purpose": "intent_fallback"
            },
            "response": api_response.raw_response,
        })
        
        if api_response.success and api_response.content:
            return self._parse_llm_intent_response(api_response.content)
        else:
            self.logger.error(f"LLM intent fallback failed: {api_response.error_message}")
            return self._create_unknown_intent_result(user_input)
            
    except Exception as e:
        self.logger.error(f"LLM intent fallback error: {e}")
        return self._create_unknown_intent_result(user_input)
```

**éªŒè¯æ–¹æ³•**ï¼š
- å•ç‹¬æµ‹è¯•æ¯ä¸ªæ–¹æ³•çš„åŠŸèƒ½
- éªŒè¯APIè°ƒç”¨å’Œå“åº”è§£æ
- æµ‹è¯•å¼‚å¸¸å¤„ç†é€»è¾‘

#### æ­¥éª¤3ï¼šé›†æˆLLMå›é€€åˆ°ä¸»æµç¨‹

**æ“ä½œä½ç½®**ï¼š`dialogue_manager/engine.py` - `process_input` æ–¹æ³•

**å…·ä½“æ“ä½œ**ï¼š
åœ¨æ„å›¾è¯†åˆ«åæ·»åŠ å›é€€é€»è¾‘ï¼š
```python
# åœ¨ process_input æ–¹æ³•ä¸­ï¼Œæ„å›¾è¯†åˆ«åæ·»åŠ ï¼š
if (self.config.llm_fallback_enabled and 
    intent_result["confidence"] < self.config.min_confidence_for_llm):
    
    self.logger.info(f"Low confidence ({intent_result['confidence']}), trying LLM fallback")
    llm_result = self._get_intent_from_llm(user_input, self.context, debug_info)
    
    if llm_result["confidence"] > intent_result["confidence"]:
        intent_result = llm_result
        debug_info["llm_fallback_used"] = True
        self.logger.info(f"LLM fallback improved confidence: {llm_result['confidence']}")
```

**éªŒè¯æ–¹æ³•**ï¼š
- æµ‹è¯•ä½ç½®ä¿¡åº¦åœºæ™¯è§¦å‘å›é€€
- éªŒè¯é«˜ç½®ä¿¡åº¦åœºæ™¯ä¸è§¦å‘å›é€€
- æ£€æŸ¥debugä¿¡æ¯è®°å½•æ­£ç¡®

### é˜¶æ®µäºŒï¼šæˆæœ¬æ§åˆ¶å’Œç›‘æ§ï¼ˆé¢„è®¡1å¤©ï¼‰

#### æ­¥éª¤4ï¼šå®ç°é¢„ç®—æ§åˆ¶æœºåˆ¶

**æ“ä½œä½ç½®**ï¼š`dialogue_manager/engine.py` - `DialogueEngine` ç±»

**å…·ä½“æ“ä½œ**ï¼š
1. æ·»åŠ ä¼šè¯çº§tokenè®¡æ•°å™¨
2. å®ç°é¢„ç®—æ£€æŸ¥é€»è¾‘
3. æ·»åŠ è¶…é¢„ç®—è‡ªåŠ¨ç¦ç”¨æœºåˆ¶

**ä»£ç æ¨¡æ¿**ï¼š
```python
def __init__(self, api_key: str, config: Optional[EngineConfig] = None):
    # ... ç°æœ‰åˆå§‹åŒ–ä»£ç  ...
    self.session_token_usage = 0  # ä¼šè¯çº§tokenä½¿ç”¨é‡
    self.llm_fallback_disabled = False  # é¢„ç®—è¶…é™æ ‡å¿—

def _check_budget_limit(self) -> bool:
    """æ£€æŸ¥æ˜¯å¦è¶…å‡ºé¢„ç®—é™åˆ¶"""
    if self.session_token_usage >= self.config.per_session_budget:
        if not self.llm_fallback_disabled:
            self.logger.warning(f"Session budget exceeded: {self.session_token_usage}")
            self.llm_fallback_disabled = True
        return False
    return True
```

**éªŒè¯æ–¹æ³•**ï¼š
- æ¨¡æ‹Ÿé«˜tokenä½¿ç”¨åœºæ™¯
- éªŒè¯é¢„ç®—è¶…é™æ—¶è‡ªåŠ¨ç¦ç”¨
- æµ‹è¯•é¢„ç®—é‡ç½®æœºåˆ¶

#### æ­¥éª¤5ï¼šæ·»åŠ æ€§èƒ½ç›‘æ§

**æ“ä½œä½ç½®**ï¼š`dialogue_manager/engine.py`

**å…·ä½“æ“ä½œ**ï¼š
1. è®°å½•LLMè°ƒç”¨æ¬¡æ•°å’Œè€—æ—¶
2. ç»Ÿè®¡å›é€€è§¦å‘ç‡å’ŒæˆåŠŸç‡
3. ç›‘æ§å“åº”æ—¶é—´åˆ†å¸ƒ

**éªŒè¯æ–¹æ³•**ï¼š
- æ£€æŸ¥ç›‘æ§æ•°æ®å‡†ç¡®æ€§
- éªŒè¯æ€§èƒ½æŒ‡æ ‡è®¡ç®—æ­£ç¡®

### é˜¶æ®µä¸‰ï¼šæµ‹è¯•å’ŒéªŒè¯ï¼ˆé¢„è®¡1å¤©ï¼‰

#### æ­¥éª¤6ï¼šç¼–å†™å•å…ƒæµ‹è¯•

**æ“ä½œä½ç½®**ï¼š`tests/test_llm_fallback.py`ï¼ˆæ–°å»ºæ–‡ä»¶ï¼‰

**æµ‹è¯•ç”¨ä¾‹**ï¼š
1. æµ‹è¯•LLMå›é€€è§¦å‘æ¡ä»¶
2. æµ‹è¯•APIè°ƒç”¨æˆåŠŸå’Œå¤±è´¥åœºæ™¯
3. æµ‹è¯•JSONè§£æå’ŒéªŒè¯
4. æµ‹è¯•é¢„ç®—æ§åˆ¶æœºåˆ¶
5. æµ‹è¯•è¶…æ—¶å¤„ç†

**ä»£ç æ¨¡æ¿**ï¼š
```python
import unittest
from unittest.mock import Mock, patch
from dialogue_manager.engine import DialogueEngine, EngineConfig

class TestLLMFallback(unittest.TestCase):
    
    def setUp(self):
        config = EngineConfig(
            llm_fallback_enabled=True,
            min_confidence_for_llm=0.4,
            llm_timeout=3
        )
        self.engine = DialogueEngine("test_key", config)
        self.engine.start_session("test_user")
    
    def test_llm_fallback_trigger(self):
        """æµ‹è¯•LLMå›é€€è§¦å‘æ¡ä»¶"""
        # æ¨¡æ‹Ÿä½ç½®ä¿¡åº¦æ„å›¾è¯†åˆ«ç»“æœ
        with patch.object(self.engine.intent_recognizer, 'recognize') as mock_recognize:
            mock_recognize.return_value = {
                "intent": "unknown",
                "confidence": 0.3,  # ä½äºé˜ˆå€¼
                "entities": [],
                "need_clarification": True
            }
            
            with patch.object(self.engine, '_get_intent_from_llm') as mock_llm:
                mock_llm.return_value = {
                    "intent": "device_control",
                    "confidence": 0.8,
                    "entities": [{"entity_type": "device", "value": "ç¯"}]
                }
                
                response, debug_info = self.engine.process_input("æ¨¡ç³Šçš„æŒ‡ä»¤")
                
                # éªŒè¯LLMå›é€€è¢«è°ƒç”¨
                mock_llm.assert_called_once()
                self.assertTrue(debug_info.get("llm_fallback_used", False))
```

#### æ­¥éª¤7ï¼šé›†æˆæµ‹è¯•

**æ“ä½œ**ï¼š
1. è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
2. éªŒè¯æ–°åŠŸèƒ½ä¸å½±å“ç°æœ‰åŠŸèƒ½
3. æµ‹è¯•ç«¯åˆ°ç«¯åœºæ™¯

**å‘½ä»¤**ï¼š
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python -m pytest tests/ -v

# è¿è¡Œç‰¹å®šçš„LLMå›é€€æµ‹è¯•
python -m pytest tests/test_llm_fallback.py -v

# è¿è¡Œæ€§èƒ½æµ‹è¯•
python -m pytest tests/test_performance.py -v
```

## ğŸ¯ 3. é¢„æœŸè¾“å‡ºç»“æœ

### åŠŸèƒ½è¾“å‡º
1. **LLMå›é€€åŠŸèƒ½**ï¼šä½ç½®ä¿¡åº¦æ—¶è‡ªåŠ¨è§¦å‘LLMæ„å›¾è¯†åˆ«
2. **æˆæœ¬æ§åˆ¶**ï¼šé¢„ç®—è¶…é™æ—¶è‡ªåŠ¨ç¦ç”¨å›é€€åŠŸèƒ½
3. **ç›‘æ§æ•°æ®**ï¼šè¯¦ç»†çš„æ€§èƒ½å’Œä½¿ç”¨ç»Ÿè®¡
4. **è°ƒè¯•ä¿¡æ¯**ï¼šå®Œæ•´çš„APIè°ƒç”¨å’Œå†³ç­–é“¾è®°å½•

### ä»£ç è¾“å‡º
1. **æ–°å¢æ–¹æ³•**ï¼š4ä¸ªLLMç›¸å…³æ–¹æ³•
2. **é…ç½®æ‰©å±•**ï¼š5ä¸ªæ–°é…ç½®å‚æ•°
3. **æµ‹è¯•ç”¨ä¾‹**ï¼šè‡³å°‘10ä¸ªæµ‹è¯•åœºæ™¯
4. **æ–‡æ¡£æ›´æ–°**ï¼šAPIæ–‡æ¡£å’Œé…ç½®è¯´æ˜

### æ€§èƒ½è¾“å‡º
1. **å“åº”æ—¶é—´**ï¼šP95 â‰¤ 2.5sï¼ˆåŒ…å«LLMè°ƒç”¨ï¼‰
2. **å‡†ç¡®ç‡æå‡**ï¼šå¤æ‚æŒ‡ä»¤è¯†åˆ«ç‡æå‡5%+
3. **ç¨³å®šæ€§**ï¼šæµ‹è¯•é€šè¿‡ç‡ä¿æŒ100%

## âœ… 4. å®Œæˆæ ‡å‡†

### åŠŸèƒ½å®Œæˆæ ‡å‡†
- [ ] LLMå›é€€æœºåˆ¶æ­£å¸¸å·¥ä½œ
- [ ] é¢„ç®—æ§åˆ¶æœºåˆ¶æœ‰æ•ˆ
- [ ] è¶…æ—¶å¤„ç†æ­£ç¡®
- [ ] å¼‚å¸¸å¤„ç†å®Œå–„
- [ ] é…ç½®å‚æ•°ç”Ÿæ•ˆ

### è´¨é‡å®Œæˆæ ‡å‡†
- [ ] æ‰€æœ‰æ–°å¢ä»£ç æœ‰å•å…ƒæµ‹è¯•è¦†ç›–
- [ ] æµ‹è¯•é€šè¿‡ç‡100%
- [ ] ä»£ç ç¬¦åˆé¡¹ç›®è§„èŒƒ
- [ ] æ€§èƒ½æŒ‡æ ‡è¾¾æ ‡
- [ ] æ–‡æ¡£æ›´æ–°å®Œæ•´

### éªŒæ”¶æµ‹è¯•æ¸…å•
```bash
# 1. åŸºç¡€åŠŸèƒ½æµ‹è¯•
python -c "from dialogue_manager.engine import DialogueEngine, EngineConfig; print('Import OK')"

# 2. é…ç½®æµ‹è¯•
python -c "from dialogue_manager.engine import EngineConfig; c=EngineConfig(); print(f'LLM enabled: {c.llm_fallback_enabled}')"

# 3. å®Œæ•´æµ‹è¯•å¥—ä»¶
python -m pytest tests/ -v --tb=short

# 4. æ€§èƒ½åŸºå‡†æµ‹è¯•
python -m pytest tests/test_performance.py::TestPerformance::test_response_time -v

# 5. LLMå›é€€åŠŸèƒ½æµ‹è¯•
python debug_llm_fallback.py  # éœ€è¦åˆ›å»ºæ­¤è°ƒè¯•è„šæœ¬
```

## ğŸ”§ 5. é—®é¢˜æ’æŸ¥æŒ‡å¼•

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### é—®é¢˜1ï¼šLLMå›é€€ä¸è§¦å‘
**ç—‡çŠ¶**ï¼šä½ç½®ä¿¡åº¦åœºæ™¯ä¸‹LLMå›é€€æœªè¢«è°ƒç”¨

**æ’æŸ¥æ­¥éª¤**ï¼š
1. æ£€æŸ¥ `llm_fallback_enabled` é…ç½®æ˜¯å¦ä¸º `True`
2. éªŒè¯ç½®ä¿¡åº¦æ˜¯å¦ä½äº `min_confidence_for_llm` é˜ˆå€¼
3. æ£€æŸ¥é¢„ç®—æ˜¯å¦å·²è¶…é™ï¼ˆ`llm_fallback_disabled` æ ‡å¿—ï¼‰
4. æŸ¥çœ‹æ—¥å¿—ä¸­çš„ç½®ä¿¡åº¦å’Œè§¦å‘æ¡ä»¶è®°å½•

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# è°ƒè¯•ä»£ç 
print(f"Config enabled: {engine.config.llm_fallback_enabled}")
print(f"Confidence: {intent_result['confidence']} vs threshold: {engine.config.min_confidence_for_llm}")
print(f"Budget disabled: {engine.llm_fallback_disabled}")
```

#### é—®é¢˜2ï¼šAPIè°ƒç”¨å¤±è´¥
**ç—‡çŠ¶**ï¼šLLM APIè°ƒç”¨è¿”å›é”™è¯¯æˆ–è¶…æ—¶

**æ’æŸ¥æ­¥éª¤**ï¼š
1. æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ
2. éªŒè¯ç½‘ç»œè¿æ¥
3. æ£€æŸ¥APIé…é¢å’Œé™åˆ¶
4. æŸ¥çœ‹APIå“åº”é”™è¯¯ä¿¡æ¯

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# æµ‹è¯•APIè¿æ¥
from dialogue_manager.api_client import SiliconFlowClient
client = SiliconFlowClient("your_api_key")
response = client.chat_completion([{"role": "user", "content": "test"}])
print(f"API test result: {response.success}, {response.error_message}")
```

#### é—®é¢˜3ï¼šJSONè§£æå¤±è´¥
**ç—‡çŠ¶**ï¼šLLMè¿”å›çš„å†…å®¹æ— æ³•è§£æä¸ºæœ‰æ•ˆJSON

**æ’æŸ¥æ­¥éª¤**ï¼š
1. æ£€æŸ¥LLMæç¤ºæ˜¯å¦æ˜ç¡®è¦æ±‚JSONæ ¼å¼
2. éªŒè¯è¿”å›å†…å®¹çš„æ ¼å¼
3. æ£€æŸ¥å¿…è¦å­—æ®µæ˜¯å¦å­˜åœ¨

**è§£å†³æ–¹æ¡ˆ**ï¼š
- ä¼˜åŒ–æç¤ºæ¨¡æ¿ï¼Œå¼ºè°ƒJSONæ ¼å¼è¦æ±‚
- æ·»åŠ æ›´ä¸¥æ ¼çš„JSONéªŒè¯
- å®ç°é™çº§å¤„ç†æœºåˆ¶

#### é—®é¢˜4ï¼šæ€§èƒ½é—®é¢˜
**ç—‡çŠ¶**ï¼šå“åº”æ—¶é—´è¿‡é•¿æˆ–è¶…æ—¶

**æ’æŸ¥æ­¥éª¤**ï¼š
1. æ£€æŸ¥LLMè°ƒç”¨è€—æ—¶
2. éªŒè¯è¶…æ—¶é…ç½®
3. åˆ†æå¹¶å‘å¤„ç†æƒ…å†µ

**è§£å†³æ–¹æ¡ˆ**ï¼š
- è°ƒæ•´ `llm_timeout` é…ç½®
- ä¼˜åŒ–æç¤ºé•¿åº¦
- å®ç°å¼‚æ­¥å¤„ç†ï¼ˆåç»­ç‰ˆæœ¬ï¼‰

### è°ƒè¯•å·¥å…·å’Œå‘½ä»¤

#### åˆ›å»ºè°ƒè¯•è„šæœ¬
**æ–‡ä»¶**ï¼š`debug_llm_fallback.py`
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from dialogue_manager.engine import DialogueEngine, EngineConfig

def debug_llm_fallback():
    """è°ƒè¯•LLMå›é€€åŠŸèƒ½"""
    config = EngineConfig(
        llm_fallback_enabled=True,
        min_confidence_for_llm=0.4,
        enable_device_manager=True
    )
    
    engine = DialogueEngine("your_api_key_here", config)
    engine.start_session('debug_user')
    
    # æµ‹è¯•ä½ç½®ä¿¡åº¦è¾“å…¥
    test_inputs = [
        "æ¨¡ç³Šçš„æŒ‡ä»¤",
        "ä¸å¤ªæ¸…æ¥šçš„è¦æ±‚",
        "å¤æ‚çš„è¡¨è¾¾"
    ]
    
    for user_input in test_inputs:
        print(f"\n=== æµ‹è¯•è¾“å…¥: '{user_input}' ===")
        response, debug_info = engine.process_input(user_input)
        
        print(f"å“åº”: {response}")
        print(f"LLMå›é€€ä½¿ç”¨: {debug_info.get('llm_fallback_used', False)}")
        print(f"ç½®ä¿¡åº¦: {debug_info['intent_result']['confidence']}")
        
        if 'api_calls' in debug_info:
            print(f"APIè°ƒç”¨æ¬¡æ•°: {len(debug_info['api_calls'])}")

if __name__ == "__main__":
    debug_llm_fallback()
```

#### æ—¥å¿—é…ç½®
```python
# åœ¨engine.pyä¸­æ·»åŠ è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# åœ¨å…³é”®ä½ç½®æ·»åŠ æ—¥å¿—
logger.debug(f"Intent confidence: {intent_result['confidence']}")
logger.info(f"LLM fallback triggered for input: {user_input}")
logger.error(f"LLM API call failed: {error_message}")
```

## ğŸ“š 6. ç›¸å…³å‚è€ƒèµ„æ–™

### é¡¹ç›®æ–‡æ¡£
- [æ”¹è¿›æŒ‡å—ä¸»æ–‡æ¡£](./dialogue_system_improvement_guide.md)
- [APIå®¢æˆ·ç«¯æ–‡æ¡£](./dialogue_manager/api_client.py)
- [æ„å›¾è¯†åˆ«æ–‡æ¡£](./dialogue_manager/intent.py)
- [å¼•æ“æ ¸å¿ƒæ–‡æ¡£](./dialogue_manager/engine.py)

### æµ‹è¯•å‚è€ƒ
- [ç°æœ‰æµ‹è¯•ç”¨ä¾‹](./tests/)
- [è®¾å¤‡ç®¡ç†å™¨æµ‹è¯•](./tests/test_device_manager.py)
- [å¯¹è¯ç„¦ç‚¹æµ‹è¯•](./tests/test_dialogue_focus.py)
- [å•å…ƒæµ‹è¯•æ¡†æ¶](./tests/test_unit.py)

### æŠ€æœ¯æ–‡æ¡£
- [SiliconFlow APIæ–‡æ¡£](https://docs.siliconflow.cn/)
- [Pythonå¼‚æ­¥ç¼–ç¨‹](https://docs.python.org/3/library/asyncio.html)
- [pytestæµ‹è¯•æ¡†æ¶](https://docs.pytest.org/)
- [JSON SchemaéªŒè¯](https://json-schema.org/)

### é…ç½®ç¤ºä¾‹
```yaml
# config/development.yaml
engine:
  min_confidence_for_llm: 0.4
  llm_fallback_enabled: true
  llm_timeout: 3
  per_turn_max_tokens: 500
  per_session_budget: 1000
  enable_context_entity_fill: true
  focus_switch_policy: "conservative"
  
api:
  model_name: "deepseek-chat"
  timeout: 30
  max_retries: 3
  
logging:
  level: "DEBUG"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
```

## ğŸ“‹ 7. è¿›åº¦è¿½è¸ªæ¸…å•

### å¼€å‘è¿›åº¦
- [ ] æ­¥éª¤1ï¼šæ·»åŠ LLMå›é€€é…ç½®å‚æ•°
- [ ] æ­¥éª¤2ï¼šå®ç°LLMæ„å›¾è¯†åˆ«æ–¹æ³•
- [ ] æ­¥éª¤3ï¼šé›†æˆLLMå›é€€åˆ°ä¸»æµç¨‹
- [ ] æ­¥éª¤4ï¼šå®ç°é¢„ç®—æ§åˆ¶æœºåˆ¶
- [ ] æ­¥éª¤5ï¼šæ·»åŠ æ€§èƒ½ç›‘æ§
- [ ] æ­¥éª¤6ï¼šç¼–å†™å•å…ƒæµ‹è¯•
- [ ] æ­¥éª¤7ï¼šé›†æˆæµ‹è¯•

### éªŒæ”¶æ¸…å•
- [ ] åŠŸèƒ½å®Œæˆæ ‡å‡†ï¼ˆ5é¡¹ï¼‰
- [ ] è´¨é‡å®Œæˆæ ‡å‡†ï¼ˆ5é¡¹ï¼‰
- [ ] éªŒæ”¶æµ‹è¯•æ¸…å•ï¼ˆ5é¡¹ï¼‰

### æ–‡æ¡£æ›´æ–°
- [ ] APIæ–‡æ¡£æ›´æ–°
- [ ] é…ç½®è¯´æ˜æ›´æ–°
- [ ] ä½¿ç”¨ç¤ºä¾‹æ›´æ–°
- [ ] æ•…éšœæ’æŸ¥æŒ‡å—

---

**æ³¨æ„äº‹é¡¹**ï¼š
1. åœ¨å¼€å§‹å®æ–½å‰ï¼Œè¯·ç¡®ä¿å½“å‰ä»£ç åº“æ˜¯æœ€æ–°ç‰ˆæœ¬
2. å»ºè®®åˆ›å»ºfeatureåˆ†æ”¯è¿›è¡Œå¼€å‘ï¼š`git checkout -b feature/llm-fallback`
3. æ¯å®Œæˆä¸€ä¸ªæ­¥éª¤åï¼Œè¿è¡Œæµ‹è¯•ç¡®ä¿åŠŸèƒ½æ­£å¸¸
4. é‡åˆ°é—®é¢˜æ—¶ï¼Œä¼˜å…ˆæŸ¥çœ‹æ—¥å¿—å’Œè°ƒè¯•ä¿¡æ¯
5. å®Œæˆåè®°å¾—æ›´æ–°ç›¸å…³æ–‡æ¡£å’Œç¤ºä¾‹ä»£ç 

**é¢„è®¡å®Œæˆæ—¶é—´**ï¼š6ä¸ªå·¥ä½œæ—¥
**é£é™©ç­‰çº§**ï¼šä¸­ç­‰
**ä¾èµ–é¡¹**ï¼šSiliconFlow APIè®¿é—®æƒé™